# app_vocacional.py
import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, util
import torch
import os

# --- Configuraci√≥n de la P√°gina ---
# st.set_page_config se usa para configurar el t√≠tulo de la pesta√±a del navegador, el √≠cono y el layout.
st.set_page_config(page_title="Orientador Vocacional AI", page_icon="üéì", layout="centered")

# --- Caching de Recursos ---
# El caching es VITAL para el rendimiento de una app de Streamlit.
# @st.cache_resource se usa para cosas que no cambian y no quieres recargar cada vez, como un modelo de ML.
@st.cache_resource
def load_model():
    """Carga el modelo de sentence-transformers desde el cache."""
    print("Cargando modelo de embeddings...")
    model = SentenceTransformer('all-MiniLM-L6-v2')
    print("Modelo cargado.")
    return model

# @st.cache_data se usa para datos que no cambian, como un CSV o los embeddings.
@st.cache_data
def load_data():
    """Carga los datos de vocaciones y los embeddings pre-calculados desde el cache."""
    print("Cargando datos y embeddings...")
    
    # Rutas a los archivos
    csv_file = "vocations_processed.csv"
    npy_file = "vocation_embeddings.npy"

    if not os.path.exists(csv_file) or not os.path.exists(npy_file):
        st.error(f"Error: No se encontraron los archivos necesarios ('{csv_file}', '{npy_file}').")
        st.error("Por favor, aseg√∫rate de ejecutar los scripts de preparaci√≥n de datos y generaci√≥n de embeddings primero.")
        return None, None

    df = pd.read_csv(csv_file)
    embeddings = np.load(npy_file)
    print("Datos y embeddings cargados.")
    return df, torch.tensor(embeddings)

# --- Carga Principal ---
# Se llama a las funciones de carga. Gracias al cache, esto solo se ejecutar√° la primera vez que inicies la app.
model = load_model()
df_vocations, vocation_embeddings = load_data()


# --- Interfaz de Usuario (UI) ---
st.title("üéì Orientador Vocacional AI")
st.write(
    "¬°Bienvenido a tu asistente de orientaci√≥n vocacional! Describe en el siguiente cuadro "
    "tus intereses, pasatiempos, las materias que te gustan y lo que te imaginas haciendo en el futuro."
)

# Verificamos si los datos se cargaron correctamente antes de continuar
if df_vocations is not None and vocation_embeddings is not None:
    # √Årea de texto para la entrada del usuario
    user_input = st.text_area(
        "Escribe aqu√≠ sobre ti:",
        height=170,
        placeholder="Ej: Me encantan los videojuegos, especialmente el dise√±o de personajes y mundos. Soy bueno dibujando y se me da bien la tecnolog√≠a. Me gusta trabajar en equipo para crear cosas nuevas y visualmente atractivas."
    )

    # Bot√≥n para iniciar la b√∫squeda de vocaciones
    if st.button("‚ú® Encontrar mi Vocaci√≥n"):
        if user_input:
            # Usamos un spinner para que el usuario sepa que algo est√° pasando
            with st.spinner("Analizando tu perfil y buscando las mejores opciones..."):
                # 1. Generar embedding para la entrada del usuario
                user_embedding = model.encode(user_input, convert_to_tensor=True)

                # 2. Calcular la similitud del coseno
                cosine_scores = util.cos_sim(user_embedding, vocation_embeddings)

                # 3. Obtener los N mejores resultados (en este caso, 10)
                top_results = torch.topk(cosine_scores[0], k=10)

                st.success("¬°An√°lisis completado! Aqu√≠ est√°n tus recomendaciones principales:")

                # 4. Mostrar los resultados

                for score, idx in zip(top_results[0], top_results[1]):
                    vocation = df_vocations.iloc[idx.item()]

                    
                    # Usamos st.expander para un dise√±o m√°s limpio
                    with st.expander(f"**{vocation['Title']}** (Similitud: {score:.0%})"):
                        st.write(f"**Descripci√≥n:** {vocation['Description']}")
                        
                        # Mostramos algunas tareas para dar m√°s contexto
                        tasks = str(vocation.get('Task Statements', 'No hay tareas espec√≠ficas disponibles.')).split('.')
                        if tasks:
                            st.write("**Algunas tareas incluyen:**")
                            # Mostramos un m√°ximo de 3 tareas para no saturar
                            for task in tasks[:3]:
                                if task.strip():
                                    st.markdown(f"- {task.strip()}")

        else:
            # Advertencia si el usuario no ha escrito nada
            st.warning("Por favor, escribe algo sobre ti para poder darte una recomendaci√≥n.")

# streamlit run app_vocacional.py